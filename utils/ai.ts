'use server';
import OpenAI from 'openai';
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});
import { getProductsClient } from '@/action/product';
import { productInformation } from '@/types/product';

export async function askSkinExpert(
  question: string
): Promise<ReadableStream<Uint8Array>> {

  const prowuctInfo=await getProductsClient() as unknown as productInformation[]


  const prompt = `
  рждрзБржорж┐ ржПржХржЬржи ржЕржнрж┐ржЬрзНржЮ рж╕рзНржХрж┐ржи ржХрзЗрзЯрж╛рж░ ржмрж┐рж╢рзЗрж╖ржЬрзНржЮред ржЗржЙржЬрж╛рж░рзЗрж░ рж╕рзНржХрж┐ржи рж╕ржорж╕рзНржпрж╛рж░ ржнрж┐рждрзНрждрж┐рждрзЗ рж╢рзБржзрзБржорж╛рждрзНрж░ ржирж┐ржЪрзЗрж░ ржкрзНрж░рзЛржбрж╛ржХрзНржЯ рждрж╛рж▓рж┐ржХрж╛ ржерзЗржХрзЗ рж╕ржмржЪрзЗрзЯрзЗ ржЙржкржпрзБржХрзНржд ржкрзНрж░рзЛржбрж╛ржХрзНржЯ рж╕рж╛ржЬрзЗрж╕рзНржЯ ржХрж░ржмрзЗред 
  
  ЁЯУМ **ржирж┐рж░рзНржжрзЗрж╢ржирж╛:**
  1. ржЗржЙржЬрж╛рж░рзЗрж░ рж╕рзНржХрж┐ржи рж╕ржорж╕рзНржпрж╛ ржнрж╛рж▓рзЛржнрж╛ржмрзЗ ржмрзЛржЭрзЛред
  2. рж╢рзБржзрзБржорж╛рждрзНрж░ ржирж┐ржЪрзЗрж░ рждрж╛рж▓рж┐ржХрж╛рзЯ ржерж╛ржХрж╛ ржкрзНрж░рзЛржбрж╛ржХрзНржЯ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ рж╕рж╛ржЬрзЗрж╢ржи ржжрж╛ржУред
  3. ржкрзНрж░рждрзНржпрзЗржХ ржкрзНрж░рзЛржбрж╛ржХрзНржЯрзЗрж░ рж╕рзБржмрж┐ржзрж╛, ржкрзНрж░ржнрж╛ржм ржУ ржмрзНржпржмрж╣рж╛рж░рзЗрж░ рж╕ржорзЯ рж╕ржорзНржкрж░рзНржХрзЗ **ржорж╛ржЭрж╛рж░рж┐ ржжрзИрж░рзНржШрзНржпрзЗрж░ ржПржХржЯрж┐ рж╕ржВржХрзНрж╖рж┐ржкрзНржд ржмрж┐рж╢рзНрж▓рзЗрж╖ржг ржкрзНржпрж╛рж░рж╛ржЧрзНрж░рж╛ржлрзЗ** ржмрж╛ржВрж▓рж╛рзЯ рж▓рж┐ржЦржмрзЗ (ржЦрзБржм ржмрзЬ ржмрж╛ ржЫрзЛржЯ ржирзЯ)ред
  4. ржкрзНрж░рзЛржбрж╛ржХрзНржЯ рж╕рж╛ржЬрзЗрж╢ржи рж╢рзЗрж╖рзЗ **ржПржХржЯрж┐ ржкрж░рж┐рж╖рзНржХрж╛рж░ рж▓рж┐рж╕рзНржЯ ржЖржХрж╛рж░рзЗ ржкрзНрж░рзЛржбрж╛ржХрзНржЯ ржирж╛ржоржЧрзБрж▓рзЛ ржЙржкрж╕рзНржерж╛ржкржи ржХрж░ржмрзЗред**
  5. ржмрж╛рж╣рзНржпрж┐ржХ ржХрзЛржирзЛ ржкрзНрж░рзЛржбрж╛ржХрзНржЯ ржмрж╛ рждржерзНржп ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ ржпрж╛ржмрзЗ ржирж╛ред
  
  ЁЯУЭ **ржкрзНрж░рж╢рзНржи:**  
  ${question}
  
  ЁЯУж **ржкрзНрж░рзЛржбрж╛ржХрзНржЯ рждрж╛рж▓рж┐ржХрж╛:**  
  ${JSON.stringify(prowuctInfo, null, 2)}
  `;
  
  const completion = await openai.chat.completions.create({
    model: 'gpt-4o-mini',
    stream: true,
    messages: [{ role: 'user', content: prompt }],
  });

  const encoder = new TextEncoder();

  const stream = new ReadableStream({
    async start(controller) {
      for await (const chunk of completion) {
        const content = chunk.choices[0]?.delta?.content;
        if (content) {
          controller.enqueue(encoder.encode(content));
        }
      }
      controller.close();
    },
  });

  return stream;
}
